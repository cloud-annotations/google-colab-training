{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "object-detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloud-annotations/google-colab-training/blob/master/object_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZSL793i7KuM",
        "colab_type": "text"
      },
      "source": [
        "# Setup\n",
        "The only thing you **NEED** to change is `ANNOTATIONS_FOLDER`.\n",
        "\n",
        "You can easily create your own annotations for free at [Cloud Annotations](https://cloud.annotations.ai).\n",
        "\n",
        "### Steps\n",
        "1. Start a new project\n",
        "1. Choose **`localization`** as the project type\n",
        "1. Label your images and videos\n",
        "1. Export an annotation folder by clicking `File > Export as Create ML`\n",
        "1. Unzip the folder and upload it to Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVPzEKoLuEHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "# Things to change:\n",
        "ANNOTATIONS_FOLDER = 'THE_NAME_OF_YOUR_FOLDER_IN_GOOGLE_DRIVE'\n",
        "NUM_TRAIN_STEPS = 500\n",
        "################################################################################\n",
        "\n",
        "import os\n",
        "GOOGLE_DRIVE_MOUNT    = '/content/drive'\n",
        "ANNOTATIONS_PATH      = os.path.join(GOOGLE_DRIVE_MOUNT, 'My Drive', ANNOTATIONS_FOLDER)\n",
        "ANNOTATIONS_JSON_PATH = os.path.join(ANNOTATIONS_PATH, 'annotations.json')\n",
        "\n",
        "CHECKPOINT_PATH = '/content/checkpoint'\n",
        "OUTPUT_PATH     = '/content/output'\n",
        "EXPORTED_PATH   = '/content/exported'\n",
        "DATA_PATH       = '/content/data'\n",
        "\n",
        "LABEL_MAP_PATH    = os.path.join(DATA_PATH, 'label_map.pbtxt')\n",
        "TRAIN_RECORD_PATH = os.path.join(DATA_PATH, 'train.record')\n",
        "VAL_RECORD_PATH   = os.path.join(DATA_PATH, 'val.record')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XINCKkPshgz",
        "colab_type": "text"
      },
      "source": [
        "# Install the TensorFlow Object Detection API\n",
        "In order to use the TensorFlow Object Detection API, we need to clone it's GitHub Repo.\n",
        "\n",
        "### Dependencies\n",
        "Most of the dependencies required come preloaded in Google Colab. The only additional package we need to install is TensorFlow.js, which is used for converting our trained model to a model that is compatible for the web.\n",
        "\n",
        "### Protocol Buffers\n",
        "The TensorFlow Object Detection API relies on what are called `protocol buffers` (also known as `protobufs`). Protobufs are a language neutral way to describe information. That means you can write a protobuf once and then compile it to be used with other languages, like Python, Java or C.\n",
        "\n",
        "The `protoc` command used below is compiling all the protocol buffers in the `object_detection/protos` folder for Python.\n",
        "\n",
        "### Environment\n",
        "To use the object detection api we need to add it to our `PYTHONPATH` along with `slim` which contains code for training and evaluating several widely used Convolutional Neural Network (CNN) image classification models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o33_jgwGm3NV",
        "colab_type": "code",
        "outputId": "35f130e7-72e7-42bb-9c00-c772206ca362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import os\n",
        "\n",
        "!cd /content\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "!pip install --no-deps tensorflowjs==1.4.0\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "pwd = os.getcwd()\n",
        "os.environ['PYTHONPATH'] += ':%s:%s/slim' % (pwd, pwd)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'models' already exists and is not an empty directory.\n",
            "Requirement already satisfied: tensorflowjs==1.4.0 in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "/content/models/research\n",
            "/env/python:/content/models/research/:/content/models/research/slim/:`pwd`:`pwd`/slim/:/content/models/research:/content/models/research/slim/:/content/models/research:/content/models/research/slim/:/content/models/research:/content/models/research/slim\n",
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS1ZDbJ660Wv",
        "colab_type": "text"
      },
      "source": [
        "# Test the setup\n",
        "If everything was set up properly and nothing went wrong, we should be able to run this command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM8sOHwL64Rp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-DHE8xTssqT",
        "colab_type": "text"
      },
      "source": [
        "# Mount Google Drive\n",
        "In order to use files from Google Drive we need to mount it to Colab.\n",
        "\n",
        "When running this command for the first time it will ask you to open a link to accept permissions. After doing so, it will give you an authorization code that you can copy and paste below to complete the mounting process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koKy90U5KAnh",
        "colab_type": "code",
        "outputId": "6b5e34d5-af99-48b4-9f52-f743916a6d8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(GOOGLE_DRIVE_MOUNT)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISX8k0TfdDHj",
        "colab_type": "text"
      },
      "source": [
        "## Generate a Label Map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJsKCG3UdDsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Get a list of labels from the annotations.json\n",
        "labels = {}\n",
        "with open(ANNOTATIONS_JSON_PATH) as f:\n",
        "  annotations = json.load(f)\n",
        "  labels = {l['label'] for a in annotations for l in a['annotations']}\n",
        "\n",
        "# Create a file named label_map.pbtxt\n",
        "os.makedirs(DATA_PATH, exist_ok=True)\n",
        "with open(LABEL_MAP_PATH, 'w') as f:\n",
        "  # Loop through all of the labels and write each label to the file with an id\n",
        "  for idx, label in enumerate(labels):\n",
        "    f.write('item {\\n')\n",
        "    f.write(\"\\tname: '{}'\\n\".format(label))\n",
        "    f.write('\\tid: {}\\n'.format(idx + 1)) # indexes must start at 1\n",
        "    f.write('}\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siRNKiuvsz25",
        "colab_type": "text"
      },
      "source": [
        "## Generate the TFRecords\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAkOvP-gZR1x",
        "colab_type": "code",
        "outputId": "1129c1a7-3c0f-4208-ec60-e08df68a7208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        }
      },
      "source": [
        "import os\n",
        "import io\n",
        "import json\n",
        "import random\n",
        "\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import dataset_util\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "def create_tf_record(annotations, label_map, image_path, output):\n",
        "  # Create a train.record TFRecord file.\n",
        "  with tf.python_io.TFRecordWriter(output) as writer:\n",
        "    # Loop through all the training examples.\n",
        "    for annotation in annotations:\n",
        "      try:\n",
        "        # Make sure the image is actually a file\n",
        "        img_path = os.path.join(image_path, annotation['image'])   \n",
        "        if not os.path.isfile(img_path):\n",
        "          continue\n",
        "          \n",
        "        # Read in the image.\n",
        "        with tf.gfile.GFile(img_path, 'rb') as fid:\n",
        "          encoded_jpg = fid.read()\n",
        "\n",
        "        # Open the image with PIL so we can check that it's a jpeg and get the image\n",
        "        # dimensions.\n",
        "        encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "        image = PIL.Image.open(encoded_jpg_io)\n",
        "        if image.format != 'JPEG':\n",
        "          raise ValueError('Image format not JPEG')\n",
        "\n",
        "        width, height = image.size\n",
        "\n",
        "        # Initialize all the arrays.\n",
        "        xmins = []\n",
        "        xmaxs = []\n",
        "        ymins = []\n",
        "        ymaxs = []\n",
        "        classes_text = []\n",
        "        classes = []\n",
        "\n",
        "        # The class text is the label name and the class is the id. If there are 3\n",
        "        # cats in the image and 1 dog, it may look something like this:\n",
        "        # classes_text = ['Cat', 'Cat', 'Dog', 'Cat']\n",
        "        # classes      = [  1  ,   1  ,   2  ,   1  ]\n",
        "\n",
        "        # For each image, loop through all the annotations and append their values.\n",
        "        for a in annotation['annotations']:\n",
        "          coord = a['coordinates']\n",
        "          xmin = coord['x'] - (coord['width'] / 2)\n",
        "          xmax = xmin + coord['width']\n",
        "          ymin = coord['y'] - (coord['height'] / 2)\n",
        "          ymax = ymin + coord['height']\n",
        "          xmins.append(max(xmin / width, 0))\n",
        "          xmaxs.append(min(xmax / width, 1))\n",
        "          ymins.append(max(ymin / height, 0))\n",
        "          ymaxs.append(min(ymax / height, 1))\n",
        "          label = a['label']\n",
        "          classes_text.append(label.encode('utf8'))\n",
        "          classes.append(label_map[label])\n",
        "      \n",
        "        # Create the TFExample.\n",
        "        tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "          'image/height': dataset_util.int64_feature(height),\n",
        "          'image/width': dataset_util.int64_feature(width),\n",
        "          'image/filename': dataset_util.bytes_feature(annotation['image'].encode('utf8')),\n",
        "          'image/source_id': dataset_util.bytes_feature(annotation['image'].encode('utf8')),\n",
        "          'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "          'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),\n",
        "          'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "          'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "          'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "          'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "          'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "          'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "        }))\n",
        "        if tf_example:\n",
        "          # Write the TFExample to the TFRecord.\n",
        "          writer.write(tf_example.SerializeToString())\n",
        "      except ValueError:\n",
        "        print('Invalid example, ignoring.')\n",
        "        pass\n",
        "      except IOError:\n",
        "        # print(\"Can't read example, ignoring.\")\n",
        "        pass\n",
        "\n",
        "with open(ANNOTATIONS_JSON_PATH) as f:\n",
        "  annotations = json.load(f)\n",
        "  # Load the label map we created.\n",
        "  label_map = label_map_util.get_label_map_dict(LABEL_MAP_PATH)\n",
        "\n",
        "  random.seed(42)\n",
        "  random.shuffle(annotations)\n",
        "  num_train = int(0.7 * len(annotations))\n",
        "  train_examples = annotations[:num_train]\n",
        "  val_examples = annotations[num_train:]\n",
        "\n",
        "  create_tf_record(train_examples, label_map, ANNOTATIONS_PATH, TRAIN_RECORD_PATH)\n",
        "  create_tf_record(val_examples, label_map, ANNOTATIONS_PATH, VAL_RECORD_PATH)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n",
            "Can't read example, ignoring.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6DhYpAS7gX2",
        "colab_type": "text"
      },
      "source": [
        "## Download a base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHD1Jm0v7jfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "\n",
        "import six.moves.urllib as urllib\n",
        "\n",
        "# Base models can be found here: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\n",
        "download_base = 'http://download.tensorflow.org/models/object_detection/'\n",
        "model = 'ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18.tar.gz'\n",
        "tmp = '/content/checkpoint.tar.gz'\n",
        "\n",
        "if not (os.path.exists(CHECKPOINT_PATH)):\n",
        "  # Download the checkpoint\n",
        "  opener = urllib.request.URLopener()\n",
        "  opener.retrieve(download_base + model, tmp)\n",
        "\n",
        "  # Extract all the `model.ckpt` files.\n",
        "  with tarfile.open(tmp) as tar:\n",
        "    for member in tar.getmembers():\n",
        "      member.name = os.path.basename(member.name)\n",
        "      if 'model.ckpt' in member.name:\n",
        "        tar.extract(member, path=CHECKPOINT_PATH)\n",
        "\n",
        "  os.remove(tmp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXlvFvwUHrui",
        "colab_type": "text"
      },
      "source": [
        "## Model config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8CVExv6HsJS",
        "colab_type": "code",
        "outputId": "d3998932-0149-4b5a-cb25-085a0fef6cb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "import re\n",
        "\n",
        "from google.protobuf import text_format\n",
        "\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "pipeline_skeleton = '/content/models/research/object_detection/samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config'\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_skeleton)\n",
        "\n",
        "label_map = label_map_util.get_label_map_dict(LABEL_MAP_PATH)\n",
        "num_classes = len(label_map.keys())\n",
        "meta_arch = configs[\"model\"].WhichOneof(\"model\")\n",
        "\n",
        "override_dict = {\n",
        "  'model.{}.num_classes'.format(meta_arch): num_classes,\n",
        "  'train_config.batch_size': 24,\n",
        "  'train_input_path': TRAIN_RECORD_PATH,\n",
        "  'eval_input_path': VAL_RECORD_PATH,\n",
        "  'train_config.fine_tune_checkpoint': os.path.join(CHECKPOINT_PATH, 'model.ckpt'),\n",
        "  'label_map_path': LABEL_MAP_PATH\n",
        "}\n",
        "\n",
        "configs = config_util.merge_external_params_with_configs(configs, kwargs_dict=override_dict)\n",
        "pipeline_config = config_util.create_pipeline_proto_from_configs(configs)\n",
        "config_util.save_pipeline_config(pipeline_config, DATA_PATH)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Maybe overwriting model.ssd.num_classes: 3\n",
            "INFO:tensorflow:Maybe overwriting train_config.batch_size: 24\n",
            "INFO:tensorflow:Maybe overwriting train_input_path: /content/data/train.record\n",
            "INFO:tensorflow:Maybe overwriting eval_input_path: /content/data/val.record\n",
            "INFO:tensorflow:Maybe overwriting train_config.fine_tune_checkpoint: /content/checkpoint/model.ckpt\n",
            "INFO:tensorflow:Maybe overwriting label_map_path: /content/data/label_map.pbtxt\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "INFO:tensorflow:Writing pipeline config file to /content/data/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNYIZK1xVNAa",
        "colab_type": "text"
      },
      "source": [
        "## Start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv5h2bwBVO0V",
        "colab_type": "code",
        "outputId": "666fc453-0fc5-43a5-8e1d-73f28f69d55e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!rm -rf $OUTPUT_PATH\n",
        "!python -m object_detection.model_main \\\n",
        "    --pipeline_config_path=$DATA_PATH/pipeline.config \\\n",
        "    --model_dir=$OUTPUT_PATH \\\n",
        "    --num_train_steps=$NUM_TRAIN_STEPS \\\n",
        "    --num_eval_steps=100"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/slim/nets/inception_resnet_v2.py:374: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1214 18:50:53.694585 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "W1214 18:50:53.697578 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W1214 18:50:53.697701 139722179495808 model_lib.py:629] Forced number of epochs for all eval validations to be 1.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W1214 18:50:53.697801 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 500\n",
            "I1214 18:50:53.697870 139722179495808 config_util.py:488] Maybe overwriting train_steps: 500\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1214 18:50:53.697931 139722179495808 config_util.py:488] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I1214 18:50:53.697982 139722179495808 config_util.py:488] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I1214 18:50:53.698034 139722179495808 config_util.py:488] Maybe overwriting eval_num_epochs: 1\n",
            "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
            "I1214 18:50:53.698101 139722179495808 config_util.py:488] Maybe overwriting load_pretrained: True\n",
            "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
            "I1214 18:50:53.698151 139722179495808 config_util.py:498] Ignoring config override key: load_pretrained\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W1214 18:50:53.698230 139722179495808 model_lib.py:645] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "I1214 18:50:53.698294 139722179495808 model_lib.py:680] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1334e42da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I1214 18:50:53.698664 139722179495808 estimator.py:212] Using config: {'_model_dir': '/content/output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1334e42da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f1334e43e18>) includes params argument, but params are not passed to Estimator.\n",
            "W1214 18:50:53.698842 139722179495808 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f1334e43e18>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I1214 18:50:53.699552 139722179495808 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I1214 18:50:53.699693 139722179495808 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I1214 18:50:53.699892 139722179495808 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W1214 18:50:53.704456 139722179495808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W1214 18:50:53.714632 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "W1214 18:50:53.714813 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W1214 18:50:53.726437 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1214 18:50:53.727598 139722179495808 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W1214 18:50:53.734705 139722179495808 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W1214 18:50:53.734925 139722179495808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1214 18:50:53.756004 139722179495808 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\n",
            "\n",
            "W1214 18:50:54.919796 139722179495808 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
            "\n",
            "W1214 18:51:01.454442 139722179495808 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W1214 18:51:01.527641 139722179495808 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W1214 18:51:03.476069 139722179495808 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W1214 18:51:06.457764 139722179495808 api.py:332] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W1214 18:51:09.522505 139722179495808 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "W1214 18:51:09.523444 139722179495808 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1214 18:51:09.888803 139722179495808 deprecation.py:323] From /content/models/research/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n",
            "\n",
            "W1214 18:51:11.403074 139722179495808 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "W1214 18:51:11.837874 139722179495808 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1214 18:51:11.850984 139722179495808 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W1214 18:51:11.858392 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W1214 18:51:11.860231 139722179495808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W1214 18:51:13.441411 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:51:13.450967 139722179495808 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:51:13.479301 139722179495808 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:51:13.507020 139722179495808 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:51:13.535878 139722179495808 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:51:13.563830 139722179495808 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:51:13.591280 139722179495808 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "W1214 18:51:13.623260 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "W1214 18:51:13.623951 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "W1214 18:51:13.625198 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_0/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.625299 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_0/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.625350 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_0/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.625393 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_0/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.625441 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_0/weights] is not available in checkpoint\n",
            "W1214 18:51:13.625491 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_10_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.625525 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_10_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.625560 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_10_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.625593 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_10_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.625627 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_10_depthwise/depthwise_weights] is not available in checkpoint\n",
            "W1214 18:51:13.625660 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_10_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.625693 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_10_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.625726 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_10_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.625759 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_10_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.625792 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_10_pointwise/weights] is not available in checkpoint\n",
            "W1214 18:51:13.625825 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_11_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.625858 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_11_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.625890 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_11_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.625923 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_11_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.625956 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_11_depthwise/depthwise_weights] is not available in checkpoint\n",
            "W1214 18:51:13.625989 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_11_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.626021 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_11_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.626080 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_11_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.626119 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_11_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.626153 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_11_pointwise/weights] is not available in checkpoint\n",
            "W1214 18:51:13.626187 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_12_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.626219 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_12_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.626251 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_12_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.626284 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_12_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.626317 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_12_depthwise/depthwise_weights] is not available in checkpoint\n",
            "W1214 18:51:13.626350 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_12_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.626382 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_12_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.626421 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_12_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.626456 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_12_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.626489 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_12_pointwise/weights] is not available in checkpoint\n",
            "W1214 18:51:13.626522 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.626555 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.626588 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.626621 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.626653 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_depthwise/depthwise_weights] is not available in checkpoint\n",
            "W1214 18:51:13.626686 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.626719 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.626752 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.626784 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.626816 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise/weights] is not available in checkpoint\n",
            "W1214 18:51:13.626849 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.626882 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.626914 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.626947 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.626980 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights] is not available in checkpoint\n",
            "W1214 18:51:13.627012 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.627067 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.627115 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.627149 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.627182 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights] is not available in checkpoint\n",
            "W1214 18:51:13.627215 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.627247 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.627280 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.627312 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.627346 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights] is not available in checkpoint\n",
            "W1214 18:51:13.627378 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.627416 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.627449 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.627482 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.627514 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights] is not available in checkpoint\n",
            "W1214 18:51:13.627547 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.627579 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.627612 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.627644 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.627677 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights] is not available in checkpoint\n",
            "W1214 18:51:13.627713 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.627746 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.627779 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.627811 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.627843 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights] is not available in checkpoint\n",
            "W1214 18:51:13.627876 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.627907 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.627940 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.627972 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.628004 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights] is not available in checkpoint\n",
            "W1214 18:51:13.628037 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.628102 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.628138 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.628170 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.628206 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights] is not available in checkpoint\n",
            "W1214 18:51:13.628238 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_1_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.628271 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_1_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.628304 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_1_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.628336 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_1_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.628369 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_1_depthwise/depthwise_weights] is not available in checkpoint\n",
            "W1214 18:51:13.628401 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_1_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.628455 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_1_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.628488 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_1_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.628521 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_1_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.628553 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_1_pointwise/weights] is not available in checkpoint\n",
            "W1214 18:51:13.628587 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_2_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.628619 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_2_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.628652 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_2_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.628684 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_2_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.628716 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_2_depthwise/depthwise_weights] is not available in checkpoint\n",
            "W1214 18:51:13.691491 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_2_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.691596 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_2_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.691673 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_2_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.691745 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_2_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.691806 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_2_pointwise/weights] is not available in checkpoint\n",
            "W1214 18:51:13.691861 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_3_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.691914 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_3_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.691970 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_3_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.692024 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_3_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.692105 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_3_depthwise/depthwise_weights] is not available in checkpoint\n",
            "W1214 18:51:13.692159 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_3_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.692215 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_3_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.692271 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_3_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.692330 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_3_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.692390 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_3_pointwise/weights] is not available in checkpoint\n",
            "W1214 18:51:13.692461 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_4_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.692522 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_4_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.692581 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_4_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.692642 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_4_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.692700 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_4_depthwise/depthwise_weights] is not available in checkpoint\n",
            "W1214 18:51:13.692763 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_4_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.692822 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_4_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.692886 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_4_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.692950 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_4_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.693019 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_4_pointwise/weights] is not available in checkpoint\n",
            "W1214 18:51:13.693102 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_5_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.693164 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_5_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.693224 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_5_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.693283 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_5_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.693346 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_5_depthwise/depthwise_weights] is not available in checkpoint\n",
            "W1214 18:51:13.693416 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_5_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.693483 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_5_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.693547 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_5_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.693610 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_5_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.693672 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_5_pointwise/weights] is not available in checkpoint\n",
            "W1214 18:51:13.693733 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_6_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.693796 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_6_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.693855 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_6_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.693915 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_6_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.693979 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_6_depthwise/depthwise_weights] is not available in checkpoint\n",
            "W1214 18:51:13.694056 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_6_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.694123 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_6_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.694186 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_6_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.694246 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_6_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.694309 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_6_pointwise/weights] is not available in checkpoint\n",
            "W1214 18:51:13.694372 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_7_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.694454 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_7_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.694522 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_7_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.694585 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_7_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.694646 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_7_depthwise/depthwise_weights] is not available in checkpoint\n",
            "W1214 18:51:13.694709 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_7_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.694767 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_7_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.694828 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_7_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.694889 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_7_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.694951 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_7_pointwise/weights] is not available in checkpoint\n",
            "W1214 18:51:13.695009 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_8_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.695087 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_8_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.695148 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_8_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.695210 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_8_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.695271 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_8_depthwise/depthwise_weights] is not available in checkpoint\n",
            "W1214 18:51:13.695334 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_8_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.695397 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_8_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.695464 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_8_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.695518 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_8_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.695570 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_8_pointwise/weights] is not available in checkpoint\n",
            "W1214 18:51:13.695622 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_9_depthwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.695675 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_9_depthwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.695754 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_9_depthwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.695836 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_9_depthwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.695906 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_9_depthwise/depthwise_weights] is not available in checkpoint\n",
            "W1214 18:51:13.695956 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_9_pointwise/BatchNorm/beta] is not available in checkpoint\n",
            "W1214 18:51:13.696002 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_9_pointwise/BatchNorm/gamma] is not available in checkpoint\n",
            "W1214 18:51:13.696064 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_9_pointwise/BatchNorm/moving_mean] is not available in checkpoint\n",
            "W1214 18:51:13.696116 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_9_pointwise/BatchNorm/moving_variance] is not available in checkpoint\n",
            "W1214 18:51:13.696165 139722179495808 variables_helper.py:157] Variable [MobilenetV1/Conv2d_9_pointwise/weights] is not available in checkpoint\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "W1214 18:51:13.696336 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W1214 18:51:13.800341 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W1214 18:51:16.999559 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "W1214 18:51:17.005136 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "W1214 18:51:17.006312 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "W1214 18:51:17.037089 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/graph_rewriter_builder.py:36: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W1214 18:51:17.039282 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/builders/graph_rewriter_builder.py:36: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n",
            "I1214 18:51:21.380975 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n",
            "I1214 18:51:21.381437 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n",
            "I1214 18:51:21.381761 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n",
            "I1214 18:51:21.382081 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n",
            "I1214 18:51:21.382400 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n",
            "I1214 18:51:21.382717 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n",
            "I1214 18:51:21.383035 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n",
            "I1214 18:51:21.383385 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n",
            "I1214 18:51:21.383712 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n",
            "I1214 18:51:21.384060 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n",
            "I1214 18:51:21.384363 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n",
            "I1214 18:51:21.384673 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n",
            "I1214 18:51:21.384973 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n",
            "I1214 18:51:21.385288 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n",
            "I1214 18:51:21.385588 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n",
            "I1214 18:51:21.385919 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n",
            "I1214 18:51:21.386216 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n",
            "I1214 18:51:21.386514 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n",
            "I1214 18:51:21.386811 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n",
            "I1214 18:51:21.387119 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n",
            "I1214 18:51:21.387407 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n",
            "I1214 18:51:21.387722 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n",
            "I1214 18:51:21.388033 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n",
            "I1214 18:51:21.388358 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n",
            "I1214 18:51:21.388657 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n",
            "I1214 18:51:21.388976 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n",
            "I1214 18:51:21.389270 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W1214 18:51:21.399472 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
            "\n",
            "W1214 18:51:21.411054 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W1214 18:51:21.411262 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W1214 18:51:26.405658 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W1214 18:51:26.896175 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "W1214 18:51:26.896465 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1214 18:51:26.896762 139722179495808 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I1214 18:51:26.897909 139722179495808 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1214 18:51:29.943517 139722179495808 monitored_session.py:240] Graph was finalized.\n",
            "2019-12-14 18:51:29.948702: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-12-14 18:51:29.948923: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x16b18c40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-14 18:51:29.948956: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-12-14 18:51:29.951085: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-12-14 18:51:30.054936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:51:30.055653: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x16b18a80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-14 18:51:30.055684: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2019-12-14 18:51:30.055902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:51:30.056451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-12-14 18:51:30.056785: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-14 18:51:30.058375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-14 18:51:30.060066: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2019-12-14 18:51:30.060458: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2019-12-14 18:51:30.062071: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2019-12-14 18:51:30.062772: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2019-12-14 18:51:30.066212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-12-14 18:51:30.066326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:51:30.066889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:51:30.067481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-12-14 18:51:30.067545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-14 18:51:30.068775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-12-14 18:51:30.068802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-12-14 18:51:30.068812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-12-14 18:51:30.068924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:51:30.069480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:51:30.069970: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-12-14 18:51:30.070014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1214 18:51:33.012155 139722179495808 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1214 18:51:33.330365 139722179495808 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /content/output/model.ckpt.\n",
            "I1214 18:51:42.088319 139722179495808 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /content/output/model.ckpt.\n",
            "2019-12-14 18:51:56.519503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-14 18:51:59.476299: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "INFO:tensorflow:loss = 4.090281, step = 0\n",
            "I1214 18:52:02.546887 139722179495808 basic_session_run_hooks.py:262] loss = 4.090281, step = 0\n",
            "INFO:tensorflow:global_step/sec: 0.998545\n",
            "I1214 18:53:42.691586 139722179495808 basic_session_run_hooks.py:692] global_step/sec: 0.998545\n",
            "INFO:tensorflow:loss = 1.2443212, step = 100 (100.146 sec)\n",
            "I1214 18:53:42.692867 139722179495808 basic_session_run_hooks.py:260] loss = 1.2443212, step = 100 (100.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.14163\n",
            "I1214 18:55:10.285268 139722179495808 basic_session_run_hooks.py:692] global_step/sec: 1.14163\n",
            "INFO:tensorflow:loss = 0.9630091, step = 200 (87.594 sec)\n",
            "I1214 18:55:10.286589 139722179495808 basic_session_run_hooks.py:260] loss = 0.9630091, step = 200 (87.594 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.16424\n",
            "I1214 18:56:36.178399 139722179495808 basic_session_run_hooks.py:692] global_step/sec: 1.16424\n",
            "INFO:tensorflow:loss = 0.7226045, step = 300 (85.893 sec)\n",
            "I1214 18:56:36.179689 139722179495808 basic_session_run_hooks.py:260] loss = 0.7226045, step = 300 (85.893 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.16318\n",
            "I1214 18:58:02.149436 139722179495808 basic_session_run_hooks.py:692] global_step/sec: 1.16318\n",
            "INFO:tensorflow:loss = 0.7345129, step = 400 (85.971 sec)\n",
            "I1214 18:58:02.150532 139722179495808 basic_session_run_hooks.py:260] loss = 0.7345129, step = 400 (85.971 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 500 into /content/output/model.ckpt.\n",
            "I1214 18:59:27.166844 139722179495808 basic_session_run_hooks.py:606] Saving checkpoints for 500 into /content/output/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1214 18:59:29.304747 139722179495808 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:59:30.733843 139722179495808 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:59:30.762517 139722179495808 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:59:30.790792 139722179495808 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:59:30.818899 139722179495808 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:59:30.846983 139722179495808 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:59:30.875626 139722179495808 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n",
            "I1214 18:59:32.611493 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n",
            "I1214 18:59:32.611799 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n",
            "I1214 18:59:32.611981 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n",
            "I1214 18:59:32.612173 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n",
            "I1214 18:59:32.612345 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n",
            "I1214 18:59:32.612528 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n",
            "I1214 18:59:32.612696 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n",
            "I1214 18:59:32.612869 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n",
            "I1214 18:59:32.613035 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n",
            "I1214 18:59:32.613221 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n",
            "I1214 18:59:32.613394 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n",
            "I1214 18:59:32.613568 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n",
            "I1214 18:59:32.613734 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n",
            "I1214 18:59:32.613904 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n",
            "I1214 18:59:32.614078 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n",
            "I1214 18:59:32.614284 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n",
            "I1214 18:59:32.614471 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n",
            "I1214 18:59:32.614654 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n",
            "I1214 18:59:32.614844 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n",
            "I1214 18:59:32.615022 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n",
            "I1214 18:59:32.615207 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n",
            "I1214 18:59:32.615404 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n",
            "I1214 18:59:32.615568 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n",
            "I1214 18:59:32.615739 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n",
            "I1214 18:59:32.615901 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n",
            "I1214 18:59:32.616083 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n",
            "I1214 18:59:32.616249 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/add_fold\n",
            "I1214 18:59:32.616417 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1214 18:59:32.616580 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/add_fold\n",
            "I1214 18:59:32.616747 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1214 18:59:32.616910 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/add_fold\n",
            "I1214 18:59:32.617084 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1214 18:59:32.617249 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/add_fold\n",
            "I1214 18:59:32.617416 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1214 18:59:32.617579 139722179495808 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1214 18:59:32.639816 139722179495808 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:498: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W1214 18:59:32.832011 139722179495808 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:498: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:1044: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
            "\n",
            "W1214 18:59:32.974962 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/utils/visualization_utils.py:1044: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:484: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "W1214 18:59:33.051129 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:484: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1214 18:59:33.374952 139722179495808 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-12-14T18:59:33Z\n",
            "I1214 18:59:33.390623 139722179495808 evaluation.py:255] Starting evaluation at 2019-12-14T18:59:33Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1214 18:59:33.863275 139722179495808 monitored_session.py:240] Graph was finalized.\n",
            "2019-12-14 18:59:33.864290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:33.864568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-12-14 18:59:33.864678: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-14 18:59:33.864738: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-14 18:59:33.864762: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2019-12-14 18:59:33.864785: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2019-12-14 18:59:33.864808: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2019-12-14 18:59:33.864829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2019-12-14 18:59:33.864852: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-12-14 18:59:33.864934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:33.865273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:33.865521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-12-14 18:59:33.865574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-12-14 18:59:33.865593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-12-14 18:59:33.865608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-12-14 18:59:33.865729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:33.866031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:33.866273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/output/model.ckpt-500\n",
            "I1214 18:59:33.867277 139722179495808 saver.py:1284] Restoring parameters from /content/output/model.ckpt-500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1214 18:59:34.867904 139722179495808 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1214 18:59:35.000595 139722179495808 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 18 images.\n",
            "I1214 18:59:39.372419 139720130590464 coco_evaluation.py:205] Performing evaluation on 18 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1214 18:59:39.372856 139720130590464 coco_tools.py:115] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I1214 18:59:39.374613 139720130590464 coco_tools.py:137] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.271\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.594\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.271\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.310\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.494\n",
            "INFO:tensorflow:Finished evaluation at 2019-12-14-18:59:41\n",
            "I1214 18:59:41.409091 139722179495808 evaluation.py:275] Finished evaluation at 2019-12-14-18:59:41\n",
            "INFO:tensorflow:Saving dict for global step 500: DetectionBoxes_Precision/mAP = 0.2707159, DetectionBoxes_Precision/mAP (large) = 0.2707159, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.5941153, DetectionBoxes_Precision/mAP@.75IOU = 0.19973487, DetectionBoxes_Recall/AR@1 = 0.31019738, DetectionBoxes_Recall/AR@10 = 0.4707237, DetectionBoxes_Recall/AR@100 = 0.4944079, DetectionBoxes_Recall/AR@100 (large) = 0.4944079, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.5311393, Loss/localization_loss = 0.302325, Loss/regularization_loss = 0.31042713, Loss/total_loss = 1.1438913, global_step = 500, learning_rate = 0.095, loss = 1.1438913\n",
            "I1214 18:59:41.409378 139722179495808 estimator.py:2049] Saving dict for global step 500: DetectionBoxes_Precision/mAP = 0.2707159, DetectionBoxes_Precision/mAP (large) = 0.2707159, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.5941153, DetectionBoxes_Precision/mAP@.75IOU = 0.19973487, DetectionBoxes_Recall/AR@1 = 0.31019738, DetectionBoxes_Recall/AR@10 = 0.4707237, DetectionBoxes_Recall/AR@100 = 0.4944079, DetectionBoxes_Recall/AR@100 (large) = 0.4944079, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.5311393, Loss/localization_loss = 0.302325, Loss/regularization_loss = 0.31042713, Loss/total_loss = 1.1438913, global_step = 500, learning_rate = 0.095, loss = 1.1438913\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 500: /content/output/model.ckpt-500\n",
            "I1214 18:59:42.169147 139722179495808 estimator.py:2109] Saving 'checkpoint_path' summary for global step 500: /content/output/model.ckpt-500\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "I1214 18:59:42.169968 139722179495808 exporter.py:410] Performing the final export in the end of training.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:750: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W1214 18:59:42.174082 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/inputs.py:750: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1214 18:59:42.374302 139722179495808 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:59:43.731001 139722179495808 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:59:43.760092 139722179495808 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:59:43.788764 139722179495808 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:59:43.817152 139722179495808 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:59:43.845554 139722179495808 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:59:43.874675 139722179495808 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:426: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "W1214 18:59:44.340937 139722179495808 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:426: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1214 18:59:44.486484 139722179495808 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W1214 18:59:44.486758 139722179495808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "I1214 18:59:44.487416 139722179495808 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "I1214 18:59:44.487548 139722179495808 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "I1214 18:59:44.487634 139722179495808 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "I1214 18:59:44.487701 139722179495808 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "I1214 18:59:44.487764 139722179495808 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "2019-12-14 18:59:44.488285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:44.488589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-12-14 18:59:44.488669: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-14 18:59:44.488695: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-14 18:59:44.488719: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2019-12-14 18:59:44.488741: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2019-12-14 18:59:44.488763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2019-12-14 18:59:44.488784: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2019-12-14 18:59:44.488805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-12-14 18:59:44.488885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:44.489272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:44.489532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-12-14 18:59:44.489574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-12-14 18:59:44.489589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-12-14 18:59:44.489600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-12-14 18:59:44.489690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:44.489996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:44.490280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/output/model.ckpt-500\n",
            "I1214 18:59:44.492766 139722179495808 saver.py:1284] Restoring parameters from /content/output/model.ckpt-500\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "I1214 18:59:44.773556 139722179495808 builder_impl.py:665] Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I1214 18:59:44.773754 139722179495808 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /content/output/export/Servo/temp-b'1576349982'/saved_model.pb\n",
            "I1214 18:59:45.342099 139722179495808 builder_impl.py:425] SavedModel written to: /content/output/export/Servo/temp-b'1576349982'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 0.6019031.\n",
            "I1214 18:59:45.690760 139722179495808 estimator.py:371] Loss for final step: 0.6019031.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwNtvgtdoB-C",
        "colab_type": "text"
      },
      "source": [
        "## Export frozen graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZgP_FZUoE0d",
        "colab_type": "code",
        "outputId": "17ea3b47-5ebd-43c8-bd33-053ebeebb57e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "regex = re.compile(r\"model\\.ckpt-([0-9]+)\\.index\")\n",
        "numbers = [int(regex.search(f).group(1)) for f in os.listdir(OUTPUT_PATH) if regex.search(f)]\n",
        "TRAINED_CHECKPOINT_PREFIX = os.path.join(OUTPUT_PATH, 'model.ckpt-{}'.format(max(numbers)))\n",
        "\n",
        "!python -m object_detection.export_inference_graph \\\n",
        "  --pipeline_config_path=$DATA_PATH/pipeline.config \\\n",
        "  --trained_checkpoint_prefix=$TRAINED_CHECKPOINT_PREFIX \\\n",
        "  --output_directory=$EXPORTED_PATH"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/slim/nets/inception_resnet_v2.py:374: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1214 18:59:51.140379 140046749005696 module_wrapper.py:139] From /content/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W1214 18:59:51.148892 140046749005696 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W1214 18:59:51.149160 140046749005696 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W1214 18:59:51.179588 140046749005696 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W1214 18:59:51.204814 140046749005696 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W1214 18:59:51.206573 140046749005696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W1214 18:59:52.526263 140046749005696 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W1214 18:59:52.536159 140046749005696 module_wrapper.py:139] From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:59:52.536312 140046749005696 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:59:52.571600 140046749005696 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:59:52.604890 140046749005696 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:59:52.641535 140046749005696 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:59:52.677321 140046749005696 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1214 18:59:52.711770 140046749005696 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W1214 18:59:52.954869 140046749005696 deprecation.py:323] From /content/models/research/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W1214 18:59:53.427291 140046749005696 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W1214 18:59:53.427572 140046749005696 deprecation.py:323] From /content/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/graph_rewriter_builder.py:41: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W1214 18:59:53.430464 140046749005696 module_wrapper.py:139] From /content/models/research/object_detection/builders/graph_rewriter_builder.py:41: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n",
            "I1214 18:59:54.286278 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n",
            "I1214 18:59:54.286572 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n",
            "I1214 18:59:54.286736 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n",
            "I1214 18:59:54.286890 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n",
            "I1214 18:59:54.287055 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n",
            "I1214 18:59:54.287204 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n",
            "I1214 18:59:54.287337 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n",
            "I1214 18:59:54.287473 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n",
            "I1214 18:59:54.287600 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n",
            "I1214 18:59:54.287736 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n",
            "I1214 18:59:54.287900 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n",
            "I1214 18:59:54.288034 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n",
            "I1214 18:59:54.288187 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n",
            "I1214 18:59:54.288324 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n",
            "I1214 18:59:54.288452 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n",
            "I1214 18:59:54.288590 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n",
            "I1214 18:59:54.288712 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n",
            "I1214 18:59:54.288840 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n",
            "I1214 18:59:54.289029 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n",
            "I1214 18:59:54.289256 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n",
            "I1214 18:59:54.289399 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n",
            "I1214 18:59:54.289563 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n",
            "I1214 18:59:54.289695 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n",
            "I1214 18:59:54.289822 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n",
            "I1214 18:59:54.289943 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n",
            "I1214 18:59:54.290084 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n",
            "I1214 18:59:54.290216 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/add_fold\n",
            "I1214 18:59:54.290340 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1214 18:59:54.290462 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/add_fold\n",
            "I1214 18:59:54.290584 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1214 18:59:54.290705 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/add_fold\n",
            "I1214 18:59:54.290835 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1214 18:59:54.290981 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/add_fold\n",
            "I1214 18:59:54.291122 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1214 18:59:54.291288 140046749005696 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W1214 18:59:54.292806 140046749005696 deprecation.py:323] From /content/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W1214 18:59:54.293683 140046749005696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "182 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/5.52m params)\n",
            "  BoxPredictor_0 (--/12.31k params)\n",
            "    BoxPredictor_0/BoxEncodingPredictor (--/6.16k params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n",
            "    BoxPredictor_0/ClassPredictor (--/6.16k params)\n",
            "      BoxPredictor_0/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_0/ClassPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n",
            "  BoxPredictor_1 (--/49.20k params)\n",
            "    BoxPredictor_1/BoxEncodingPredictor (--/24.60k params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1024x24, 24.58k/24.58k params)\n",
            "    BoxPredictor_1/ClassPredictor (--/24.60k params)\n",
            "      BoxPredictor_1/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_1/ClassPredictor/weights (1x1x1024x24, 24.58k/24.58k params)\n",
            "  BoxPredictor_2 (--/24.62k params)\n",
            "    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "    BoxPredictor_2/ClassPredictor (--/12.31k params)\n",
            "      BoxPredictor_2/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_2/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "  BoxPredictor_3 (--/12.34k params)\n",
            "    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_3/ClassPredictor (--/6.17k params)\n",
            "      BoxPredictor_3/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_3/ClassPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "  BoxPredictor_4 (--/12.34k params)\n",
            "    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_4/ClassPredictor (--/6.17k params)\n",
            "      BoxPredictor_4/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_4/ClassPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "  BoxPredictor_5 (--/6.19k params)\n",
            "    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
            "    BoxPredictor_5/ClassPredictor (--/3.10k params)\n",
            "      BoxPredictor_5/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_5/ClassPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
            "  FeatureExtractor (--/5.41m params)\n",
            "    FeatureExtractor/MobilenetV1 (--/5.41m params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_0 (--/864 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_0/weights (3x3x3x32, 864/864 params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_10_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_10_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_11_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_11_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_12_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_12_pointwise (--/524.29k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights (1x1x512x1024, 524.29k/524.29k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_depthwise (--/9.22k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights (3x3x1024x1, 9.22k/9.22k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise (--/1.05m params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights (1x1x1024x1024, 1.05m/1.05m params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256 (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128 (--/65.54k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64 (--/16.38k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_1_depthwise (--/288 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_1_pointwise (--/2.05k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights (1x1x32x64, 2.05k/2.05k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_2_depthwise (--/576 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights (3x3x64x1, 576/576 params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_2_pointwise (--/8.19k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights (1x1x64x128, 8.19k/8.19k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_3_depthwise (--/1.15k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_3_pointwise (--/16.38k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights (1x1x128x128, 16.38k/16.38k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_4_depthwise (--/1.15k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_4_pointwise (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights (1x1x128x256, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_5_depthwise (--/2.30k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_5_pointwise (--/65.54k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights (1x1x256x256, 65.54k/65.54k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_6_depthwise (--/2.30k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_6_pointwise (--/131.07k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights (1x1x256x512, 131.07k/131.07k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_7_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_7_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_8_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_8_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_9_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_9_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "\n",
            "======================End of Report==========================\n",
            "182 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/5.42m flops)\n",
            "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/mul_fold (1.18m/1.18m flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/mul_fold (1.05m/1.05m flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/mul_fold (524.29k/524.29k flops)\n",
            "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/mul_fold (294.91k/294.91k flops)\n",
            "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/mul_fold (294.91k/294.91k flops)\n",
            "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/mul_fold (262.14k/262.14k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/mul_fold (262.14k/262.14k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/mul_fold (262.14k/262.14k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/mul_fold (262.14k/262.14k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/mul_fold (262.14k/262.14k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/mul_fold (262.14k/262.14k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/mul_fold (131.07k/131.07k flops)\n",
            "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/mul_fold (73.73k/73.73k flops)\n",
            "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/mul_fold (65.54k/65.54k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/mul_fold (65.54k/65.54k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/mul_fold (32.77k/32.77k flops)\n",
            "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/mul_fold (32.77k/32.77k flops)\n",
            "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/mul_fold (16.38k/16.38k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/mul_fold (16.38k/16.38k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/mul_fold (9.22k/9.22k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/mul_fold (8.19k/8.19k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/mul_fold (4.61k/4.61k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/mul_fold (4.61k/4.61k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/mul_fold (4.61k/4.61k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/mul_fold (4.61k/4.61k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/mul_fold (4.61k/4.61k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/mul_fold (4.61k/4.61k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/mul_fold (2.30k/2.30k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/mul_fold (2.30k/2.30k flops)\n",
            "  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/mul_fold (2.05k/2.05k flops)\n",
            "  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/mul_fold (1.15k/1.15k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/mul_fold (1.15k/1.15k flops)\n",
            "  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/mul_fold (864/864 flops)\n",
            "  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/mul_fold (576/576 flops)\n",
            "  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n",
            "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/mul_fold (288/288 flops)\n",
            "  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n",
            "  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n",
            "  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n",
            "  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n",
            "  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W1214 18:59:55.297091 140046749005696 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W1214 18:59:56.168451 140046749005696 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-12-14 18:59:56.169715: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-12-14 18:59:56.191250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:56.191883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-12-14 18:59:56.192180: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-14 18:59:56.193721: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-14 18:59:56.202864: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2019-12-14 18:59:56.203231: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2019-12-14 18:59:56.204985: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2019-12-14 18:59:56.208488: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2019-12-14 18:59:56.212675: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-12-14 18:59:56.212820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:56.213389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:56.213910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-12-14 18:59:56.218772: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-12-14 18:59:56.218940: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2a80d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-14 18:59:56.218966: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-12-14 18:59:56.311446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:56.312240: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2a80f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-14 18:59:56.312289: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2019-12-14 18:59:56.312471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:56.313068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-12-14 18:59:56.313136: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-14 18:59:56.313160: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-14 18:59:56.313181: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2019-12-14 18:59:56.313203: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2019-12-14 18:59:56.313223: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2019-12-14 18:59:56.313242: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2019-12-14 18:59:56.313261: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-12-14 18:59:56.313327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:56.313850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:56.314343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-12-14 18:59:56.314422: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-14 18:59:56.315551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-12-14 18:59:56.315576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-12-14 18:59:56.315586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-12-14 18:59:56.315684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:56.316238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:56.316723: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-12-14 18:59:56.316762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/output/model.ckpt-500\n",
            "I1214 18:59:56.318333 140046749005696 saver.py:1284] Restoring parameters from /content/output/model.ckpt-500\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W1214 18:59:57.974617 140046749005696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2019-12-14 18:59:58.623877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:58.624503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-12-14 18:59:58.624585: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-14 18:59:58.624608: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-14 18:59:58.624630: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2019-12-14 18:59:58.624651: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2019-12-14 18:59:58.624671: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2019-12-14 18:59:58.624689: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2019-12-14 18:59:58.624709: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-12-14 18:59:58.624789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:58.625381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:58.625856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-12-14 18:59:58.625896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-12-14 18:59:58.625909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-12-14 18:59:58.625918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-12-14 18:59:58.626009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:58.626585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:58.627087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/output/model.ckpt-500\n",
            "I1214 18:59:58.628174 140046749005696 saver.py:1284] Restoring parameters from /content/output/model.ckpt-500\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W1214 18:59:59.265696 140046749005696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W1214 18:59:59.265972 140046749005696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 387 variables.\n",
            "I1214 18:59:59.643899 140046749005696 graph_util_impl.py:334] Froze 387 variables.\n",
            "INFO:tensorflow:Converted 387 variables to const ops.\n",
            "I1214 18:59:59.723715 140046749005696 graph_util_impl.py:394] Converted 387 variables to const ops.\n",
            "2019-12-14 18:59:59.872309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:59.872927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-12-14 18:59:59.873017: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-14 18:59:59.873061: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-14 18:59:59.873084: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2019-12-14 18:59:59.873106: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2019-12-14 18:59:59.873126: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2019-12-14 18:59:59.873147: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2019-12-14 18:59:59.873167: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-12-14 18:59:59.873250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:59.873831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:59.874346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-12-14 18:59:59.874388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-12-14 18:59:59.874402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-12-14 18:59:59.874412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-12-14 18:59:59.874505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:59.875052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-14 18:59:59.875535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "W1214 19:00:00.276620 140046749005696 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/models/research/object_detection/export_inference_graph.py\", line 162, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/models/research/object_detection/export_inference_graph.py\", line 158, in main\n",
            "    write_inference_graph=FLAGS.write_inference_graph)\n",
            "  File \"/content/models/research/object_detection/exporter.py\", line 510, in export_inference_graph\n",
            "    write_inference_graph=write_inference_graph)\n",
            "  File \"/content/models/research/object_detection/exporter.py\", line 466, in _export_inference_graph\n",
            "    placeholder_tensor, outputs)\n",
            "  File \"/content/models/research/object_detection/exporter.py\", line 306, in write_saved_model\n",
            "    builder = tf.saved_model.builder.SavedModelBuilder(saved_model_path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/builder_impl.py\", line 436, in __init__\n",
            "    super(SavedModelBuilder, self).__init__(export_dir=export_dir)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/builder_impl.py\", line 103, in __init__\n",
            "    \"specified directory: %s\" % export_dir)\n",
            "AssertionError: Export directory already exists, and isn't empty. Please choose a different export directory, or delete all the contents of the specified directory: /content/exported/saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVmCc9NPkP3U",
        "colab_type": "text"
      },
      "source": [
        "## Convert the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-f5lfcnp01e",
        "colab_type": "code",
        "outputId": "807acda6-ad05-4bd2-b2d1-8d1a14fb3bb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "!tensorflowjs_converter \\\n",
        "  --input_format=tf_frozen_model \\\n",
        "  --output_format=tfjs_graph_model \\\n",
        "  --output_node_names='Postprocessor/ExpandDims_1,Postprocessor/Slice' \\\n",
        "  --quantization_bytes=1 \\\n",
        "  --skip_op_check \\\n",
        "  $EXPORTED_PATH/frozen_inference_graph.pb \\\n",
        "  /content/model_web\n",
        "\n",
        "import json\n",
        "\n",
        "from object_detection.utils.label_map_util import get_label_map_dict\n",
        "\n",
        "label_map = get_label_map_dict(LABEL_MAP_PATH)\n",
        "label_array = [k for k in sorted(label_map, key=label_map.get)]\n",
        "\n",
        "with open(os.path.join('/content/model_web', 'labels.json'), 'w') as f:\n",
        "  json.dump(label_array, f)\n",
        "\n",
        "!cd /content/model_web && zip -r /content/model_web.zip *"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-14 19:00:04.675515: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize\n",
            "2019-12-14 19:00:04.675569: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   debug_stripper: Graph size after: 3226 nodes (0), 3947 edges (0), time = 2.603ms.\n",
            "2019-12-14 19:00:04.675579: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   model_pruner: Graph size after: 2100 nodes (-1126), 2355 edges (-1592), time = 15.413ms.\n",
            "2019-12-14 19:00:04.675591: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 625 nodes (-1475), 687 edges (-1668), time = 214.242ms.\n",
            "2019-12-14 19:00:04.675602: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   arithmetic_optimizer: Graph size after: 482 nodes (-143), 646 edges (-41), time = 39.66ms.\n",
            "2019-12-14 19:00:04.675613: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   dependency_optimizer: Graph size after: 476 nodes (-6), 639 edges (-7), time = 11.405ms.\n",
            "2019-12-14 19:00:04.675623: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   model_pruner: Graph size after: 476 nodes (0), 639 edges (0), time = 15.652ms.\n",
            "2019-12-14 19:00:04.675634: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 476 nodes (0), 639 edges (0), time = 89.482ms.\n",
            "2019-12-14 19:00:04.675644: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   arithmetic_optimizer: Graph size after: 474 nodes (-2), 635 edges (-4), time = 36.225ms.\n",
            "2019-12-14 19:00:04.675655: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   dependency_optimizer: Graph size after: 474 nodes (0), 635 edges (0), time = 12.194ms.\n",
            "2019-12-14 19:00:04.675665: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   debug_stripper: debug_stripper did nothing. time = 0.622ms.\n",
            "2019-12-14 19:00:04.675675: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   model_pruner: Graph size after: 474 nodes (0), 635 edges (0), time = 14.879ms.\n",
            "2019-12-14 19:00:04.675686: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 474 nodes (0), 635 edges (0), time = 47.145ms.\n",
            "2019-12-14 19:00:04.675696: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   arithmetic_optimizer: Graph size after: 474 nodes (0), 635 edges (0), time = 36.89ms.\n",
            "2019-12-14 19:00:04.675707: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   dependency_optimizer: Graph size after: 474 nodes (0), 635 edges (0), time = 9.622ms.\n",
            "2019-12-14 19:00:04.675717: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   model_pruner: Graph size after: 474 nodes (0), 635 edges (0), time = 14.196ms.\n",
            "2019-12-14 19:00:04.675728: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 474 nodes (0), 635 edges (0), time = 46.805ms.\n",
            "2019-12-14 19:00:04.675739: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   arithmetic_optimizer: Graph size after: 474 nodes (0), 635 edges (0), time = 37.341ms.\n",
            "2019-12-14 19:00:04.675750: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   dependency_optimizer: Graph size after: 474 nodes (0), 635 edges (0), time = 9.982ms.\n",
            "2019-12-14 19:00:05.461842: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize\n",
            "2019-12-14 19:00:05.461895: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   remapper: Graph size after: 462 nodes (-12), 623 edges (-12), time = 25.434ms.\n",
            "2019-12-14 19:00:05.461904: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 462 nodes (0), 623 edges (0), time = 57.331ms.\n",
            "2019-12-14 19:00:05.461912: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   arithmetic_optimizer: Graph size after: 462 nodes (0), 623 edges (0), time = 41.926ms.\n",
            "2019-12-14 19:00:05.461920: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   dependency_optimizer: Graph size after: 462 nodes (0), 623 edges (0), time = 10.017ms.\n",
            "2019-12-14 19:00:05.461927: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   remapper: Graph size after: 462 nodes (0), 623 edges (0), time = 14.78ms.\n",
            "2019-12-14 19:00:05.461934: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 462 nodes (0), 623 edges (0), time = 45.038ms.\n",
            "2019-12-14 19:00:05.461942: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   arithmetic_optimizer: Graph size after: 462 nodes (0), 623 edges (0), time = 37.766ms.\n",
            "2019-12-14 19:00:05.461949: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   dependency_optimizer: Graph size after: 462 nodes (0), 623 edges (0), time = 10.677ms.\n",
            "Writing weight file /content/model_web/model.json...\n",
            "updating: group1-shard1of2.bin (deflated 27%)\n",
            "updating: group1-shard2of2.bin (deflated 25%)\n",
            "updating: labels.json (deflated 4%)\n",
            "updating: model.json (deflated 93%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1iFI9pPr1l7",
        "colab_type": "text"
      },
      "source": [
        "## Download the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL_miSj2r1yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/model_web.zip') "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}